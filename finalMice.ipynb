{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2fe2c80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:05.518344Z",
     "iopub.status.busy": "2025-12-15T17:37:05.518042Z",
     "iopub.status.idle": "2025-12-15T17:37:15.428073Z",
     "shell.execute_reply": "2025-12-15T17:37:15.427242Z"
    },
    "papermill": {
     "duration": 9.917687,
     "end_time": "2025-12-15T17:37:15.429558",
     "exception": false,
     "start_time": "2025-12-15T17:37:05.511871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a77c429",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:15.439598Z",
     "iopub.status.busy": "2025-12-15T17:37:15.438727Z",
     "iopub.status.idle": "2025-12-15T17:37:17.132561Z",
     "shell.execute_reply": "2025-12-15T17:37:17.131933Z"
    },
    "papermill": {
     "duration": 1.700102,
     "end_time": "2025-12-15T17:37:17.133960",
     "exception": false,
     "start_time": "2025-12-15T17:37:15.433858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.base import clone\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import warnings\n",
    "import optuna\n",
    "import joblib\n",
    "import glob\n",
    "import gc\n",
    "import os\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "053dce54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:17.143138Z",
     "iopub.status.busy": "2025-12-15T17:37:17.142832Z",
     "iopub.status.idle": "2025-12-15T17:37:17.711851Z",
     "shell.execute_reply": "2025-12-15T17:37:17.711250Z"
    },
    "papermill": {
     "duration": 0.575107,
     "end_time": "2025-12-15T17:37:17.713194",
     "exception": false,
     "start_time": "2025-12-15T17:37:17.138087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"F Beta customized for the data format of the MABe challenge.\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "class HostVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def single_lab_f1(lab_solution: pl.DataFrame, lab_submission: pl.DataFrame, beta: float = 1) -> float:\n",
    "    label_frames: defaultdict[str, set[int]] = defaultdict(set)\n",
    "    prediction_frames: defaultdict[str, set[int]] = defaultdict(set)\n",
    "\n",
    "    for row in lab_solution.to_dicts():\n",
    "        label_frames[row['label_key']].update(range(row['start_frame'], row['stop_frame']))\n",
    "\n",
    "    for video in lab_solution['video_id'].unique():\n",
    "        active_labels: str = lab_solution.filter(pl.col('video_id') == video)['behaviors_labeled'].first()  # ty: ignore\n",
    "        active_labels: set[str] = set(json.loads(active_labels))\n",
    "        predicted_mouse_pairs: defaultdict[str, set[int]] = defaultdict(set)\n",
    "\n",
    "        for row in lab_submission.filter(pl.col('video_id') == video).to_dicts():\n",
    "            # Since the labels are sparse, we can't evaluate prediction keys not in the active labels.\n",
    "            if ','.join([str(row['agent_id']), str(row['target_id']), row['action']]) not in active_labels:\n",
    "                continue\n",
    "\n",
    "            new_frames = set(range(row['start_frame'], row['stop_frame']))\n",
    "            # Ignore truly redundant predictions.\n",
    "            new_frames = new_frames.difference(prediction_frames[row['prediction_key']])\n",
    "            prediction_pair = ','.join([str(row['agent_id']), str(row['target_id'])])\n",
    "            if predicted_mouse_pairs[prediction_pair].intersection(new_frames):\n",
    "                # A single agent can have multiple targets per frame (ex: evading all other mice) but only one action per target per frame.\n",
    "                raise HostVisibleError('Multiple predictions for the same frame from one agent/target pair')\n",
    "            prediction_frames[row['prediction_key']].update(new_frames)\n",
    "            predicted_mouse_pairs[prediction_pair].update(new_frames)\n",
    "\n",
    "    tps = defaultdict(int)\n",
    "    fns = defaultdict(int)\n",
    "    fps = defaultdict(int)\n",
    "    for key, pred_frames in prediction_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        matched_label_frames = label_frames[key]\n",
    "        tps[action] += len(pred_frames.intersection(matched_label_frames))\n",
    "        fns[action] += len(matched_label_frames.difference(pred_frames))\n",
    "        fps[action] += len(pred_frames.difference(matched_label_frames))\n",
    "\n",
    "    distinct_actions = set()\n",
    "    for key, frames in label_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        distinct_actions.add(action)\n",
    "        if key not in prediction_frames:\n",
    "            fns[action] += len(frames)\n",
    "\n",
    "    action_f1s = []\n",
    "    for action in distinct_actions:\n",
    "        if tps[action] + fns[action] + fps[action] == 0:\n",
    "            action_f1s.append(0)\n",
    "        else:\n",
    "            action_f1s.append((1 + beta**2) * tps[action] / ((1 + beta**2) * tps[action] + beta**2 * fns[action] + fps[action]))\n",
    "    return sum(action_f1s) / len(action_f1s)\n",
    "\n",
    "\n",
    "def mouse_fbeta(solution: pd.DataFrame, submission: pd.DataFrame, beta: float = 1) -> float:\n",
    "    if len(solution) == 0 or len(submission) == 0:\n",
    "        raise ValueError('Missing solution or submission data')\n",
    "\n",
    "    expected_cols = ['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']\n",
    "\n",
    "    for col in expected_cols:\n",
    "        if col not in solution.columns:\n",
    "            raise ValueError(f'Solution is missing column {col}')\n",
    "        if col not in submission.columns:\n",
    "            raise ValueError(f'Submission is missing column {col}')\n",
    "\n",
    "    solution: pl.DataFrame = pl.DataFrame(solution)\n",
    "    submission: pl.DataFrame = pl.DataFrame(submission)\n",
    "    assert (solution['start_frame'] <= solution['stop_frame']).all()\n",
    "    assert (submission['start_frame'] <= submission['stop_frame']).all()\n",
    "    solution_videos = set(solution['video_id'].unique())\n",
    "    # Need to align based on video IDs as we can't rely on the row IDs for handling public/private splits.\n",
    "    submission = submission.filter(pl.col('video_id').is_in(solution_videos))\n",
    "\n",
    "    solution = solution.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('label_key'),\n",
    "    )\n",
    "    submission = submission.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('prediction_key'),\n",
    "    )\n",
    "\n",
    "    lab_scores = []\n",
    "    for lab in solution['lab_id'].unique():\n",
    "        lab_solution = solution.filter(pl.col('lab_id') == lab).clone()\n",
    "        lab_videos = set(lab_solution['video_id'].unique())\n",
    "        lab_submission = submission.filter(pl.col('video_id').is_in(lab_videos)).clone()\n",
    "        lab_scores.append(single_lab_f1(lab_solution, lab_submission, beta=beta))\n",
    "\n",
    "    return sum(lab_scores) / len(lab_scores)\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, beta: float = 1) -> float:\n",
    "    \"\"\"\n",
    "    F1 score for the MABe Challenge\n",
    "    \"\"\"\n",
    "    solution = solution.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    submission = submission.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    return mouse_fbeta(solution, submission, beta=beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f6a9d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:17.722434Z",
     "iopub.status.busy": "2025-12-15T17:37:17.721885Z",
     "iopub.status.idle": "2025-12-15T17:37:17.726593Z",
     "shell.execute_reply": "2025-12-15T17:37:17.725874Z"
    },
    "papermill": {
     "duration": 0.01048,
     "end_time": "2025-12-15T17:37:17.727671",
     "exception": false,
     "start_time": "2025-12-15T17:37:17.717191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # train_path = \"MABe-mouse-behavior-detection/train.csv\" 로컬환경\n",
    "    train_path = \"/kaggle/input/MABe-mouse-behavior-detection/train.csv\"\n",
    "    test_path = \"/kaggle/input/MABe-mouse-behavior-detection/test.csv\"\n",
    "    train_annotation_path = \"/kaggle/input/MABe-mouse-behavior-detection/train_annotation\"\n",
    "    train_tracking_path = \"/kaggle/input/MABe-mouse-behavior-detection/train_tracking\"\n",
    "    test_tracking_path = \"/kaggle/input/MABe-mouse-behavior-detection/test_tracking\"\n",
    "\n",
    "    # moedl_path = \"models\" 로컬환경\n",
    "    model_path = \"/kaggle/input/model-weights/models\"\n",
    "    model_name = \"xgboost\" \n",
    "    \n",
    "    # mode = \"validate\"\n",
    "    mode = \"submit\"\n",
    "    \n",
    "    n_splits = 2\n",
    "    cv = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    xgb_params = {\n",
    "        'n_estimators': 300,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 6,\n",
    "        'n_jobs': -1,\n",
    "        'tree_method': 'hist',\n",
    "        'random_state': 42,\n",
    "        'eval_metric': 'logloss',\n",
    "        'device': 'cuda' # GPU사용 설정 MAC애서는 안됨\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eae341c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:17.736510Z",
     "iopub.status.busy": "2025-12-15T17:37:17.735952Z",
     "iopub.status.idle": "2025-12-15T17:37:17.862018Z",
     "shell.execute_reply": "2025-12-15T17:37:17.861206Z"
    },
    "papermill": {
     "duration": 0.131672,
     "end_time": "2025-12-15T17:37:17.863269",
     "exception": false,
     "start_time": "2025-12-15T17:37:17.731597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[\"body_center\", \"ear_left\", \"ear_right\", \"forepaw_left\", \"forepaw_right\", \"hindpaw_left\", \"hindpaw_right\", \"neck\", \"nose\", \"tail_base\", \"tail_midpoint\", \"tail_tip\"]',\n",
       " '[\"body_center\", \"ear_left\", \"ear_right\", \"headpiece_bottombackleft\", \"headpiece_bottombackright\", \"headpiece_bottomfrontleft\", \"headpiece_bottomfrontright\", \"headpiece_topbackleft\", \"headpiece_topbackright\", \"headpiece_topfrontleft\", \"headpiece_topfrontright\", \"lateral_left\", \"lateral_right\", \"neck\", \"nose\", \"tail_base\", \"tail_midpoint\", \"tail_tip\"]',\n",
       " '[\"body_center\", \"ear_left\", \"ear_right\", \"hip_left\", \"hip_right\", \"lateral_left\", \"lateral_right\", \"nose\", \"spine_1\", \"spine_2\", \"tail_base\", \"tail_middle_1\", \"tail_middle_2\", \"tail_tip\"]',\n",
       " '[\"body_center\", \"ear_left\", \"ear_right\", \"lateral_left\", \"lateral_right\", \"neck\", \"nose\", \"tail_base\", \"tail_midpoint\", \"tail_tip\"]',\n",
       " '[\"body_center\", \"ear_left\", \"ear_right\", \"lateral_left\", \"lateral_right\", \"nose\", \"tail_base\", \"tail_tip\"]',\n",
       " '[\"body_center\", \"ear_left\", \"ear_right\", \"lateral_left\", \"lateral_right\", \"nose\", \"tail_base\"]',\n",
       " '[\"body_center\", \"ear_left\", \"ear_right\", \"nose\", \"tail_base\"]',\n",
       " '[\"ear_left\", \"ear_right\", \"head\", \"tail_base\"]',\n",
       " '[\"ear_left\", \"ear_right\", \"hip_left\", \"hip_right\", \"neck\", \"nose\", \"tail_base\"]',\n",
       " '[\"ear_left\", \"ear_right\", \"nose\", \"tail_base\", \"tail_tip\"]']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(CFG.train_path)\n",
    "train['n_mice'] = 4 - train[['mouse1_strain', 'mouse2_strain', 'mouse3_strain', 'mouse4_strain']].isna().sum(axis=1)\n",
    "train_without_mabe22 = train.query(\"~lab_id.str.startswith('MABe22_')\")\n",
    "\n",
    "test = pd.read_csv(CFG.test_path)\n",
    "body_parts_tracked_list = list(np.unique(train.body_parts_tracked))\n",
    "\n",
    "body_parts_tracked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "760f7a8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:17.873200Z",
     "iopub.status.busy": "2025-12-15T17:37:17.872646Z",
     "iopub.status.idle": "2025-12-15T17:37:17.881944Z",
     "shell.execute_reply": "2025-12-15T17:37:17.881354Z"
    },
    "papermill": {
     "duration": 0.01519,
     "end_time": "2025-12-15T17:37:17.883000",
     "exception": false,
     "start_time": "2025-12-15T17:37:17.867810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load threshold file: /kaggle/input/model-weights/models/xgboost/thresholds.pkl\n"
     ]
    }
   ],
   "source": [
    "# (lab_id, video_id, behaviors_labeled, target_id, agent_id) --> 데이터구축\n",
    "\n",
    "def create_solution_df(dataset):\n",
    "    solution = []\n",
    "    for _, row in tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "    \n",
    "        lab_id = row['lab_id']\n",
    "        if lab_id.startswith('MABe22'): \n",
    "            continue\n",
    "        \n",
    "        video_id = row['video_id']\n",
    "        path = f\"{CFG.train_annotation_path}/{lab_id}/{video_id}.parquet\"\n",
    "        try:\n",
    "            annot = pd.read_parquet(path)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    \n",
    "        annot['lab_id'] = lab_id\n",
    "        annot['video_id'] = video_id\n",
    "        annot['behaviors_labeled'] = row['behaviors_labeled']\n",
    "        annot['target_id'] = np.where(annot.target_id != annot.agent_id, annot['target_id'].apply(lambda s: f\"mouse{s}\"), 'self')\n",
    "        annot['agent_id'] = annot['agent_id'].apply(lambda s: f\"mouse{s}\")\n",
    "        solution.append(annot)\n",
    "    \n",
    "    solution = pd.concat(solution)\n",
    "    \n",
    "    return solution\n",
    "\n",
    "# validate 모드일때는 thresholds를 초기화\n",
    "if CFG.mode == \"validate\":\n",
    "    thresholds = {\n",
    "        \"single\": {},\n",
    "        \"pair\": {}\n",
    "    }\n",
    "# train 모드일때는 기존에 저장된 thresholds를 load\n",
    "else:\n",
    "    try:\n",
    "        thresholds = joblib.load(f\"{CFG.model_path}/{CFG.model_name}/thresholds.pkl\")\n",
    "        print(f\"load threshold file: {CFG.model_path}/{CFG .model_name}/thresholds.pkl\")\n",
    "    except Exception as e:\n",
    "        print(f\"load threshold file failed: {e}\")\n",
    "        thresholds = {\n",
    "            \"single\": {\"default\": 0.5},\n",
    "            \"pair\": {\"default\": 0.5}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7ac10f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:17.892405Z",
     "iopub.status.busy": "2025-12-15T17:37:17.892175Z",
     "iopub.status.idle": "2025-12-15T17:37:17.905673Z",
     "shell.execute_reply": "2025-12-15T17:37:17.904965Z"
    },
    "papermill": {
     "duration": 0.019495,
     "end_time": "2025-12-15T17:37:17.906753",
     "exception": false,
     "start_time": "2025-12-15T17:37:17.887258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_body_parts =  [\n",
    "    'headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright', \n",
    "    'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright', \n",
    "    'spine_1', 'spine_2', 'tail_middle_1', 'tail_middle_2', 'tail_midpoint'\n",
    "]\n",
    "\n",
    "def generate_mouse_data(dataset, traintest, traintest_directory=None, generate_single=True, generate_pair=True):\n",
    "    # tracking 데이터 사용\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n",
    "        \n",
    "    for _, row in dataset.iterrows():\n",
    "        lab_id = row.lab_id\n",
    "        if lab_id.startswith('MABe22') or type(row.behaviors_labeled) != str: \n",
    "            continue\n",
    "        \n",
    "        video_id = row.video_id\n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\" # tracking\n",
    "        vid = pd.read_parquet(path)\n",
    "        if len(np.unique(vid.bodypart)) > 5:\n",
    "            vid = vid.query(\"~ bodypart.isin(@drop_body_parts)\")\n",
    "            \n",
    "        pvid = vid.pivot(columns=['mouse_id', 'bodypart'], index='video_frame', values=['x', 'y'])\n",
    "\n",
    "        idx = 1\n",
    "        del vid\n",
    "        gc.collect()\n",
    "        \n",
    "        pvid = pvid.reorder_levels([1, 2, 0], axis=1).T.sort_index().T\n",
    "        pvid /= row.pix_per_cm_approx\n",
    "\n",
    "        vid_behaviors = json.loads(row.behaviors_labeled)\n",
    "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
    "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n",
    "        \n",
    "        if traintest == 'train':\n",
    "            try:\n",
    "                annot = pd.read_parquet(path.replace('train_tracking', 'train_annotation'))\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "\n",
    "        if generate_single:\n",
    "            vid_behaviors_subset = vid_behaviors.query(\"target == 'self'\")\n",
    "            for mouse_id_str in np.unique(vid_behaviors_subset.agent):\n",
    "                try:\n",
    "                    mouse_id = int(mouse_id_str[-1])\n",
    "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"agent == @mouse_id_str\").action)\n",
    "                    single_mouse = pvid.loc[:, mouse_id]\n",
    "                    assert len(single_mouse) == len(pvid)\n",
    "                    single_mouse_meta = pd.DataFrame({\n",
    "                        'video_id': video_id,\n",
    "                        'agent_id': mouse_id_str,\n",
    "                        'target_id': 'self',\n",
    "                        'video_frame': single_mouse.index\n",
    "                    })\n",
    "                    if traintest == 'train':\n",
    "                        single_mouse_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=single_mouse.index)\n",
    "                        annot_subset = annot.query(\"(agent_id == @mouse_id) & (target_id == @mouse_id)\")\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            annot_row = annot_subset.iloc[i]\n",
    "                            single_mouse_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n",
    "                        yield 'single', single_mouse, single_mouse_meta, single_mouse_label\n",
    "                    else:\n",
    "                        yield 'single', single_mouse, single_mouse_meta, vid_agent_actions\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "        if generate_pair:\n",
    "            vid_behaviors_subset = vid_behaviors.query(\"target != 'self'\")\n",
    "            if len(vid_behaviors_subset) > 0:\n",
    "                for agent, target in itertools.permutations(np.unique(pvid.columns.get_level_values('mouse_id')), 2): # int8\n",
    "                    agent_str = f\"mouse{agent}\"\n",
    "                    target_str = f\"mouse{target}\"\n",
    "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"(agent == @agent_str) & (target == @target_str)\").action)\n",
    "                    mouse_pair = pd.concat([pvid[agent], pvid[target]], axis=1, keys=['A', 'B'])\n",
    "                    assert len(mouse_pair) == len(pvid)\n",
    "                    mouse_pair_meta = pd.DataFrame({\n",
    "                        'video_id': video_id,\n",
    "                        'agent_id': agent_str,\n",
    "                        'target_id': target_str,\n",
    "                        'video_frame': mouse_pair.index\n",
    "                    })\n",
    "                    if traintest == 'train':\n",
    "                        mouse_pair_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=mouse_pair.index)\n",
    "                        annot_subset = annot.query(\"(agent_id == @agent) & (target_id == @target)\")\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            annot_row = annot_subset.iloc[i]\n",
    "                            mouse_pair_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n",
    "                        yield 'pair', mouse_pair, mouse_pair_meta, mouse_pair_label\n",
    "                    else:\n",
    "                        yield 'pair', mouse_pair, mouse_pair_meta, vid_agent_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fceb039",
   "metadata": {
    "papermill": {
     "duration": 0.003988,
     "end_time": "2025-12-15T17:37:17.915022",
     "exception": false,
     "start_time": "2025-12-15T17:37:17.911034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c8bbdf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:17.924501Z",
     "iopub.status.busy": "2025-12-15T17:37:17.924005Z",
     "iopub.status.idle": "2025-12-15T17:37:17.943444Z",
     "shell.execute_reply": "2025-12-15T17:37:17.942710Z"
    },
    "papermill": {
     "duration": 0.025725,
     "end_time": "2025-12-15T17:37:17.944677",
     "exception": false,
     "start_time": "2025-12-15T17:37:17.918952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def safe_rolling(series, window, func, min_periods=None):\n",
    "    if min_periods is None:\n",
    "        min_periods = max(1, window // 4)\n",
    "    return series.rolling(window, min_periods=min_periods, center=True).apply(func, raw=True)\n",
    "\n",
    "def _scale(n_frames_at_30fps, fps, ref=30.0):\n",
    "    return max(1, int(round(n_frames_at_30fps * float(fps) / ref)))\n",
    "\n",
    "def _scale_signed(n_frames_at_30fps, fps, ref=30.0):\n",
    "    if n_frames_at_30fps == 0:\n",
    "        return 0\n",
    "    s = 1 if n_frames_at_30fps > 0 else -1\n",
    "    mag = max(1, int(round(abs(n_frames_at_30fps) * float(fps) / ref)))\n",
    "    return s * mag\n",
    "\n",
    "def _fps_from_meta(meta_df, fallback_lookup, default_fps=30.0):\n",
    "    if 'frames_per_second' in meta_df.columns and pd.notnull(meta_df['frames_per_second']).any():\n",
    "        return float(meta_df['frames_per_second'].iloc[0])\n",
    "    vid = meta_df['video_id'].iloc[0]\n",
    "    return float(fallback_lookup.get(vid, default_fps))\n",
    "\n",
    "def add_curvature_features(X, center_x, center_y, fps):\n",
    "    vel_x = center_x.diff()\n",
    "    vel_y = center_y.diff()\n",
    "    acc_x = vel_x.diff()\n",
    "    acc_y = vel_y.diff()\n",
    "\n",
    "    cross_prod = vel_x * acc_y - vel_y * acc_x\n",
    "    vel_mag = np.sqrt(vel_x**2 + vel_y**2)\n",
    "    curvature = np.abs(cross_prod) / (vel_mag**3 + 1e-6)\n",
    "\n",
    "    for w in [25, 50, 75]:\n",
    "        ws = _scale(w, fps)\n",
    "        X[f'curv_mean_{w}'] = curvature.rolling(ws, min_periods=max(1, ws // 5)).mean()\n",
    "\n",
    "    angle = np.arctan2(vel_y, vel_x)\n",
    "    angle_change = np.abs(angle.diff())\n",
    "    w = 30\n",
    "    ws = _scale(w, fps)\n",
    "    X[f'turn_rate_{w}'] = angle_change.rolling(ws, min_periods=max(1, ws // 5)).sum()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_multiscale_features(X, center_x, center_y, fps):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)\n",
    "\n",
    "    scales = [20, 40, 60, 80]\n",
    "    for scale in scales:\n",
    "        ws = _scale(scale, fps)\n",
    "        if len(speed) >= ws:\n",
    "            X[f'sp_m{scale}'] = speed.rolling(ws, min_periods=max(1, ws // 4)).mean()\n",
    "            X[f'sp_s{scale}'] = speed.rolling(ws, min_periods=max(1, ws // 4)).std()\n",
    "\n",
    "    if len(scales) >= 2 and f'sp_m{scales[0]}' in X.columns and f'sp_m{scales[-1]}' in X.columns:\n",
    "        X['sp_ratio'] = X[f'sp_m{scales[0]}'] / (X[f'sp_m{scales[-1]}'] + 1e-6)\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_state_features(X, center_x, center_y, fps):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)\n",
    "    w_ma = _scale(15, fps)\n",
    "    speed_ma = speed.rolling(w_ma, min_periods=max(1, w_ma // 3)).mean()\n",
    "\n",
    "    try:\n",
    "        bins = [-np.inf, 0.5 * fps, 2.0 * fps, 5.0 * fps, np.inf]\n",
    "        speed_states = pd.cut(speed_ma, bins=bins, labels=[0, 1, 2, 3]).astype(float)\n",
    "\n",
    "        for window in [20, 40, 60, 80]:\n",
    "            ws = _scale(window, fps)\n",
    "            if len(speed_states) >= ws:\n",
    "                for state in [0, 1, 2, 3]:\n",
    "                    X[f's{state}_{window}'] = (\n",
    "                        (speed_states == state).astype(float)\n",
    "                        .rolling(ws, min_periods=max(1, ws // 5)).mean()\n",
    "                    )\n",
    "                state_changes = (speed_states != speed_states.shift(1)).astype(float)\n",
    "                X[f'trans_{window}'] = state_changes.rolling(ws, min_periods=max(1, ws // 5)).sum()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_longrange_features(X, center_x, center_y, fps):\n",
    "    for window in [30, 60, 120]:\n",
    "        ws = _scale(window, fps)\n",
    "        if len(center_x) >= ws:\n",
    "            X[f'x_ml{window}'] = center_x.rolling(ws, min_periods=max(5, ws // 6)).mean()\n",
    "            X[f'y_ml{window}'] = center_y.rolling(ws, min_periods=max(5, ws // 6)).mean()\n",
    "\n",
    "    for span in [30, 60, 120]:\n",
    "        s = _scale(span, fps)\n",
    "        X[f'x_e{span}'] = center_x.ewm(span=s, min_periods=1).mean()\n",
    "        X[f'y_e{span}'] = center_y.ewm(span=s, min_periods=1).mean()\n",
    "\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)  # cm/s\n",
    "    for window in [30, 60, 120]:\n",
    "        ws = _scale(window, fps)\n",
    "        if len(speed) >= ws:\n",
    "            X[f'sp_pct{window}'] = speed.rolling(ws, min_periods=max(5, ws // 6)).rank(pct=True)\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_interaction_features(X, mouse_pair, avail_A, avail_B, fps):\n",
    "    if 'body_center' not in avail_A or 'body_center' not in avail_B:\n",
    "        return X\n",
    "\n",
    "    rel_x = mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x']\n",
    "    rel_y = mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y']\n",
    "    rel_dist = np.sqrt(rel_x**2 + rel_y**2)\n",
    "\n",
    "    A_vx = mouse_pair['A']['body_center']['x'].diff()\n",
    "    A_vy = mouse_pair['A']['body_center']['y'].diff()\n",
    "    B_vx = mouse_pair['B']['body_center']['x'].diff()\n",
    "    B_vy = mouse_pair['B']['body_center']['y'].diff()\n",
    "\n",
    "    A_lead = (A_vx * rel_x + A_vy * rel_y) / (np.sqrt(A_vx**2 + A_vy**2) * rel_dist + 1e-6)\n",
    "    B_lead = (B_vx * (-rel_x) + B_vy * (-rel_y)) / (np.sqrt(B_vx**2 + B_vy**2) * rel_dist + 1e-6)\n",
    "\n",
    "    for window in [30, 60]:\n",
    "        ws = _scale(window, fps)\n",
    "        X[f'A_ld{window}'] = A_lead.rolling(ws, min_periods=max(1, ws // 6)).mean()\n",
    "        X[f'B_ld{window}'] = B_lead.rolling(ws, min_periods=max(1, ws // 6)).mean()\n",
    "\n",
    "    approach = -rel_dist.diff()\n",
    "    chase = approach * B_lead\n",
    "    w = 30\n",
    "    ws = _scale(w, fps)\n",
    "    X[f'chase_{w}'] = chase.rolling(ws, min_periods=max(1, ws // 6)).mean()\n",
    "\n",
    "    for window in [60, 120]:\n",
    "        ws = _scale(window, fps)\n",
    "        A_sp = np.sqrt(A_vx**2 + A_vy**2)\n",
    "        B_sp = np.sqrt(B_vx**2 + B_vy**2)\n",
    "        X[f'sp_cor{window}'] = A_sp.rolling(ws, min_periods=max(1, ws // 6)).corr(B_sp)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce15dcf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:17.954728Z",
     "iopub.status.busy": "2025-12-15T17:37:17.954362Z",
     "iopub.status.idle": "2025-12-15T17:37:17.989373Z",
     "shell.execute_reply": "2025-12-15T17:37:17.988589Z"
    },
    "papermill": {
     "duration": 0.041587,
     "end_time": "2025-12-15T17:37:17.990630",
     "exception": false,
     "start_time": "2025-12-15T17:37:17.949043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_egocentric_transform(mouse_df, body_parts, target_points=None):\n",
    "    \"\"\"\n",
    "    Transforms coordinates to an egocentric frame based on body_center and tail_base.\n",
    "    Origin: body_center\n",
    "    Y-axis: vector from tail_base to body_center (spine points UP)\n",
    "    \"\"\"\n",
    "    if 'body_center' not in mouse_df.columns or 'tail_base' not in mouse_df.columns:\n",
    "        return None\n",
    "    \n",
    "    # 1. Translation: Center at body_center\n",
    "    origin_x = mouse_df['body_center']['x']\n",
    "    origin_y = mouse_df['body_center']['y']\n",
    "    \n",
    "    # 2. Rotation: Align spine (tail_base -> body_center) with Y-axis\n",
    "    # Vector from tail to center\n",
    "    spine_x = mouse_df['body_center']['x'] - mouse_df['tail_base']['x']\n",
    "    spine_y = mouse_df['body_center']['y'] - mouse_df['tail_base']['y']\n",
    "    \n",
    "    # Angle of spine relative to Y-axis (0, 1)\n",
    "    # We want to rotate so that (spine_x, spine_y) becomes (0, +mag)\n",
    "    # Current angle of spine in global coords\n",
    "    theta = np.arctan2(spine_y, spine_x)\n",
    "    # We want this to be pi/2 (90 degrees, pointing up)\n",
    "    # So we rotate by (pi/2 - theta)\n",
    "    rotation_angle = np.pi/2 - theta\n",
    "    \n",
    "    cos_a = np.cos(rotation_angle)\n",
    "    sin_a = np.sin(rotation_angle)\n",
    "    \n",
    "    ego_data = {}\n",
    "    \n",
    "    # Transform own body parts\n",
    "    for part in body_parts:\n",
    "        if part in mouse_df.columns:\n",
    "            # Translate\n",
    "            dx = mouse_df[part]['x'] - origin_x\n",
    "            dy = mouse_df[part]['y'] - origin_y\n",
    "            # Rotate\n",
    "            ego_data[f'ego_{part}_x'] = dx * cos_a - dy * sin_a\n",
    "            ego_data[f'ego_{part}_y'] = dx * sin_a + dy * cos_a\n",
    "            \n",
    "    # Transform target points (e.g., other mouse's body parts) if provided\n",
    "    if target_points is not None:\n",
    "        for col_name, (tx, ty) in target_points.items():\n",
    "            dx = tx - origin_x\n",
    "            dy = ty - origin_y\n",
    "            ego_data[f'ego_target_{col_name}_x'] = dx * cos_a - dy * sin_a\n",
    "            ego_data[f'ego_target_{col_name}_y'] = dx * sin_a + dy * cos_a\n",
    "            \n",
    "    return pd.DataFrame(ego_data, index=mouse_df.index)\n",
    "\n",
    "\n",
    "\n",
    "def transform_single(single_mouse, body_parts_tracked, fps):\n",
    "    available_body_parts = single_mouse.columns.get_level_values(0)\n",
    "\n",
    "    X = pd.DataFrame({\n",
    "        f\"{p1}+{p2}\": np.square(single_mouse[p1] - single_mouse[p2]).sum(axis=1, skipna=False)\n",
    "        for p1, p2 in itertools.combinations(body_parts_tracked, 2)\n",
    "        if p1 in available_body_parts and p2 in available_body_parts\n",
    "    })\n",
    "    X = X.reindex(columns=[f\"{p1}+{p2}\" for p1, p2 in itertools.combinations(body_parts_tracked, 2)], copy=False)\n",
    "\n",
    "    if all(p in single_mouse.columns for p in ['ear_left', 'ear_right', 'tail_base']):\n",
    "        lag = _scale(10, fps)\n",
    "        shifted = single_mouse[['ear_left', 'ear_right', 'tail_base']].shift(lag)\n",
    "        speeds = pd.DataFrame({\n",
    "            'sp_lf': np.square(single_mouse['ear_left'] - shifted['ear_left']).sum(axis=1, skipna=False),\n",
    "            'sp_rt': np.square(single_mouse['ear_right'] - shifted['ear_right']).sum(axis=1, skipna=False),\n",
    "            'sp_lf2': np.square(single_mouse['ear_left'] - shifted['tail_base']).sum(axis=1, skipna=False),\n",
    "            'sp_rt2': np.square(single_mouse['ear_right'] - shifted['tail_base']).sum(axis=1, skipna=False),\n",
    "        })\n",
    "        X = pd.concat([X, speeds], axis=1)\n",
    "\n",
    "    if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n",
    "        X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n",
    "\n",
    "    if all(p in available_body_parts for p in ['nose', 'body_center', 'tail_base']):\n",
    "        v1 = single_mouse['nose'] - single_mouse['body_center']\n",
    "        v2 = single_mouse['tail_base'] - single_mouse['body_center']\n",
    "        X['body_ang'] = (v1['x'] * v2['x'] + v1['y'] * v2['y']) / (\n",
    "            np.sqrt(v1['x']**2 + v1['y']**2) * np.sqrt(v2['x']**2 + v2['y']**2) + 1e-6)\n",
    "\n",
    "    if 'body_center' in available_body_parts:\n",
    "        cx = single_mouse['body_center']['x']\n",
    "        cy = single_mouse['body_center']['y']\n",
    "\n",
    "        for w in [5, 15, 30, 60]:\n",
    "            ws = _scale(w, fps)\n",
    "            roll = dict(min_periods=1, center=True)\n",
    "            X[f'cx_m{w}'] = cx.rolling(ws, **roll).mean()\n",
    "            X[f'cy_m{w}'] = cy.rolling(ws, **roll).mean()\n",
    "            X[f'cx_s{w}'] = cx.rolling(ws, **roll).std()\n",
    "            X[f'cy_s{w}'] = cy.rolling(ws, **roll).std()\n",
    "            X[f'x_rng{w}'] = cx.rolling(ws, **roll).max() - cx.rolling(ws, **roll).min()\n",
    "            X[f'y_rng{w}'] = cy.rolling(ws, **roll).max() - cy.rolling(ws, **roll).min()\n",
    "            X[f'disp{w}'] = np.sqrt(cx.diff().rolling(ws, min_periods=1).sum()**2 +\n",
    "                                     cy.diff().rolling(ws, min_periods=1).sum()**2)\n",
    "            X[f'act{w}'] = np.sqrt(cx.diff().rolling(ws, min_periods=1).var() +\n",
    "                                   cy.diff().rolling(ws, min_periods=1).var())\n",
    "\n",
    "        X = add_curvature_features(X, cx, cy, fps)\n",
    "        X = add_multiscale_features(X, cx, cy, fps)\n",
    "        X = add_state_features(X, cx, cy, fps)\n",
    "        X = add_longrange_features(X, cx, cy, fps)\n",
    "\n",
    "    if all(p in available_body_parts for p in ['nose', 'tail_base']):\n",
    "        nt_dist = np.sqrt((single_mouse['nose']['x'] - single_mouse['tail_base']['x'])**2 +\n",
    "                          (single_mouse['nose']['y'] - single_mouse['tail_base']['y'])**2)\n",
    "        for lag in [10, 20, 40]:\n",
    "            l = _scale(lag, fps)\n",
    "            X[f'nt_lg{lag}'] = nt_dist.shift(l)\n",
    "            X[f'nt_df{lag}'] = nt_dist - nt_dist.shift(l)\n",
    "\n",
    "    if all(p in available_body_parts for p in ['ear_left', 'ear_right']):\n",
    "        ear_d = np.sqrt((single_mouse['ear_left']['x'] - single_mouse['ear_right']['x'])**2 +\n",
    "                        (single_mouse['ear_left']['y'] - single_mouse['ear_right']['y'])**2)\n",
    "        for off in [-30, -20, -10, 10, 20, 30]:\n",
    "            o = _scale_signed(off, fps)\n",
    "            X[f'ear_o{off}'] = ear_d.shift(-o)\n",
    "        w = _scale(30, fps)\n",
    "        X['ear_con'] = ear_d.rolling(w, min_periods=1, center=True).std() / \\\n",
    "                       (ear_d.rolling(w, min_periods=1, center=True).mean() + 1e-6)\n",
    "    \n",
    "    # [NEW] Add Egocentric Features\n",
    "    ego_df = compute_egocentric_transform(single_mouse, body_parts_tracked)\n",
    "    if ego_df is not None:\n",
    "        X = pd.concat([X, ego_df], axis=1)\n",
    "\n",
    "    return X.astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "\n",
    "def transform_pair(mouse_pair, body_parts_tracked, fps):\n",
    "    avail_A = mouse_pair['A'].columns.get_level_values(0)\n",
    "    avail_B = mouse_pair['B'].columns.get_level_values(0)\n",
    "\n",
    "    X = pd.DataFrame({\n",
    "        f\"12+{p1}+{p2}\": np.square(mouse_pair['A'][p1] - mouse_pair['B'][p2]).sum(axis=1, skipna=False)\n",
    "        for p1, p2 in itertools.product(body_parts_tracked, repeat=2)\n",
    "        if p1 in avail_A and p2 in avail_B\n",
    "    })\n",
    "    X = X.reindex(columns=[f\"12+{p1}+{p2}\" for p1, p2 in itertools.product(body_parts_tracked, repeat=2)], copy=False)\n",
    "\n",
    "    if ('A', 'ear_left') in mouse_pair.columns and ('B', 'ear_left') in mouse_pair.columns:\n",
    "        lag = _scale(10, fps)\n",
    "        shA = mouse_pair['A']['ear_left'].shift(lag)\n",
    "        shB = mouse_pair['B']['ear_left'].shift(lag)\n",
    "        speeds = pd.DataFrame({\n",
    "            'sp_A': np.square(mouse_pair['A']['ear_left'] - shA).sum(axis=1, skipna=False),\n",
    "            'sp_AB': np.square(mouse_pair['A']['ear_left'] - shB).sum(axis=1, skipna=False),\n",
    "            'sp_B': np.square(mouse_pair['B']['ear_left'] - shB).sum(axis=1, skipna=False),\n",
    "        })\n",
    "        X = pd.concat([X, speeds], axis=1)\n",
    "\n",
    "    if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n",
    "        X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n",
    "\n",
    "    if all(p in avail_A for p in ['nose', 'tail_base']) and all(p in avail_B for p in ['nose', 'tail_base']):\n",
    "        dir_A = mouse_pair['A']['nose'] - mouse_pair['A']['tail_base']\n",
    "        dir_B = mouse_pair['B']['nose'] - mouse_pair['B']['tail_base']\n",
    "        X['rel_ori'] = (dir_A['x'] * dir_B['x'] + dir_A['y'] * dir_B['y']) / (\n",
    "            np.sqrt(dir_A['x']**2 + dir_A['y']**2) * np.sqrt(dir_B['x']**2 + dir_B['y']**2) + 1e-6)\n",
    "\n",
    "    if all(p in avail_A for p in ['nose']) and all(p in avail_B for p in ['nose']):\n",
    "        cur = np.square(mouse_pair['A']['nose'] - mouse_pair['B']['nose']).sum(axis=1, skipna=False)\n",
    "        lag = _scale(10, fps)\n",
    "        shA_n = mouse_pair['A']['nose'].shift(lag)\n",
    "        shB_n = mouse_pair['B']['nose'].shift(lag)\n",
    "        past = np.square(shA_n - shB_n).sum(axis=1, skipna=False)\n",
    "        X['appr'] = cur - past\n",
    "\n",
    "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "        cd = np.sqrt((mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x'])**2 +\n",
    "                     (mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y'])**2)\n",
    "        X['v_cls'] = (cd < 5.0).astype(float)\n",
    "        X['cls']   = ((cd >= 5.0) & (cd < 15.0)).astype(float)\n",
    "        X['med']   = ((cd >= 15.0) & (cd < 30.0)).astype(float)\n",
    "        X['far']   = (cd >= 30.0).astype(float)\n",
    "\n",
    "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "        cd_full = np.square(mouse_pair['A']['body_center'] - mouse_pair['B']['body_center']).sum(axis=1, skipna=False)\n",
    "\n",
    "        for w in [5, 15, 30, 60]:\n",
    "            ws = _scale(w, fps)\n",
    "            roll = dict(min_periods=1, center=True)\n",
    "            X[f'd_m{w}']  = cd_full.rolling(ws, **roll).mean()\n",
    "            X[f'd_s{w}']  = cd_full.rolling(ws, **roll).std()\n",
    "            X[f'd_mn{w}'] = cd_full.rolling(ws, **roll).min()\n",
    "            X[f'd_mx{w}'] = cd_full.rolling(ws, **roll).max()\n",
    "\n",
    "            d_var = cd_full.rolling(ws, **roll).var()\n",
    "            X[f'int{w}'] = 1 / (1 + d_var)\n",
    "\n",
    "            Axd = mouse_pair['A']['body_center']['x'].diff()\n",
    "            Ayd = mouse_pair['A']['body_center']['y'].diff()\n",
    "            Bxd = mouse_pair['B']['body_center']['x'].diff()\n",
    "            Byd = mouse_pair['B']['body_center']['y'].diff()\n",
    "            coord = Axd * Bxd + Ayd * Byd\n",
    "            X[f'co_m{w}'] = coord.rolling(ws, **roll).mean()\n",
    "            X[f'co_s{w}'] = coord.rolling(ws, **roll).std()\n",
    "\n",
    "    if 'nose' in avail_A and 'nose' in avail_B:\n",
    "        nn = np.sqrt((mouse_pair['A']['nose']['x'] - mouse_pair['B']['nose']['x'])**2 +\n",
    "                     (mouse_pair['A']['nose']['y'] - mouse_pair['B']['nose']['y'])**2)\n",
    "        for lag in [10, 20, 40]:\n",
    "            l = _scale(lag, fps)\n",
    "            X[f'nn_lg{lag}']  = nn.shift(l)\n",
    "            X[f'nn_ch{lag}']  = nn - nn.shift(l)\n",
    "            is_cl = (nn < 10.0).astype(float)\n",
    "            X[f'cl_ps{lag}']  = is_cl.rolling(l, min_periods=1).mean()\n",
    "\n",
    "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "        Avx = mouse_pair['A']['body_center']['x'].diff()\n",
    "        Avy = mouse_pair['A']['body_center']['y'].diff()\n",
    "        Bvx = mouse_pair['B']['body_center']['x'].diff()\n",
    "        Bvy = mouse_pair['B']['body_center']['y'].diff()\n",
    "        val = (Avx * Bvx + Avy * Bvy) / (np.sqrt(Avx**2 + Avy**2) * np.sqrt(Bvx**2 + Bvy**2) + 1e-6)\n",
    "\n",
    "        for off in [-30, -20, -10, 0, 10, 20, 30]:\n",
    "            o = _scale_signed(off, fps)\n",
    "            X[f'va_{off}'] = val.shift(-o)\n",
    "\n",
    "        w = _scale(30, fps)\n",
    "        X['int_con'] = cd_full.rolling(w, min_periods=1, center=True).std() / \\\n",
    "                       (cd_full.rolling(w, min_periods=1, center=True).mean() + 1e-6)\n",
    "\n",
    "        X = add_interaction_features(X, mouse_pair, avail_A, avail_B, fps)\n",
    "    \n",
    "    # [NEW] Add Egocentric Features for Pair\n",
    "    # 1. A's ego features (A in A's frame)\n",
    "    ego_A = compute_egocentric_transform(mouse_pair['A'], body_parts_tracked)\n",
    "    if ego_A is not None:\n",
    "        ego_A.columns = [f\"A_{c}\" for c in ego_A.columns]\n",
    "        X = pd.concat([X, ego_A], axis=1)\n",
    "        \n",
    "    # 2. B's ego features (B in B's frame) - to know B's posture\n",
    "    ego_B = compute_egocentric_transform(mouse_pair['B'], body_parts_tracked)\n",
    "    if ego_B is not None:\n",
    "        ego_B.columns = [f\"B_{c}\" for c in ego_B.columns]\n",
    "        X = pd.concat([X, ego_B], axis=1)\n",
    "\n",
    "    # 3. B in A's frame (Interaction context: where is B relative to A?)\n",
    "    if 'body_center' in mouse_pair['B'].columns:\n",
    "        # Prepare B's key points to transform into A's frame\n",
    "        target_pts = {\n",
    "            'body_center': (mouse_pair['B']['body_center']['x'], mouse_pair['B']['body_center']['y'])\n",
    "        }\n",
    "        if 'nose' in mouse_pair['B'].columns:\n",
    "            target_pts['nose'] = (mouse_pair['B']['nose']['x'], mouse_pair['B']['nose']['y'])\n",
    "            \n",
    "        ego_B_in_A = compute_egocentric_transform(mouse_pair['A'], [], target_points=target_pts)\n",
    "        if ego_B_in_A is not None:\n",
    "             X = pd.concat([X, ego_B_in_A], axis=1)\n",
    "\n",
    "    return X.astype(np.float32, copy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed4e9cea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:18.000235Z",
     "iopub.status.busy": "2025-12-15T17:37:17.999835Z",
     "iopub.status.idle": "2025-12-15T17:37:18.010884Z",
     "shell.execute_reply": "2025-12-15T17:37:18.010167Z"
    },
    "papermill": {
     "duration": 0.017011,
     "end_time": "2025-12-15T17:37:18.011985",
     "exception": false,
     "start_time": "2025-12-15T17:37:17.994974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def robustify(submission, dataset, traintest, traintest_directory=None):\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n",
    "    \n",
    "    old_submission = submission.copy()\n",
    "    \n",
    "    # --------------------------\n",
    "    # Core fix: Convert start_frame/stop_frame to integers\n",
    "    # --------------------------\n",
    "    # Handle string to int conversion（兼容 \"123\" 这类字符串，无效值转为 NaN 后填充为 0）\n",
    "    submission['start_frame'] = pd.to_numeric(submission['start_frame'], errors='coerce').fillna(0).astype(int)\n",
    "    submission['stop_frame'] = pd.to_numeric(submission['stop_frame'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # Filter invalid rows where start >= stop（现在是整数比较，无类型错误）\n",
    "    submission = submission[submission.start_frame < submission.stop_frame]\n",
    "    if len(submission) != len(old_submission):\n",
    "        print(\"ERROR: Dropped frames with start >= stop\")\n",
    "    \n",
    "    old_submission = submission.copy()\n",
    "    group_list = []\n",
    "    # Group by video_id + agent_id + target_id，避免跨主体的帧冲突\n",
    "    for _, group in submission.groupby(['video_id', 'agent_id', 'target_id']):\n",
    "        group = group.sort_values('start_frame')  # Sort by start frame\n",
    "        mask = np.ones(len(group), dtype=bool)\n",
    "        last_stop_frame = 0\n",
    "        for i, (_, row) in enumerate(group.iterrows()):\n",
    "            # 现在 start_frame 是整数，可正常比较\n",
    "            if row['start_frame'] < last_stop_frame:\n",
    "                mask[i] = False  # Filter overlapping actions（当前开始帧 < 上一个结束帧）\n",
    "            else:\n",
    "                last_stop_frame = row['stop_frame']  # Update the stop frame of the previous action\n",
    "        group_list.append(group[mask])\n",
    "        \n",
    "    submission = pd.concat(group_list)\n",
    "    \n",
    "    if len(submission) != len(old_submission):\n",
    "        print(\"ERROR: Dropped duplicate frames\")\n",
    "        \n",
    "    s_list = []\n",
    "    # Handle videos with no predictions，填充默认动作帧\n",
    "    for idx, row in dataset.iterrows():\n",
    "        lab_id = row['lab_id']\n",
    "        if lab_id.startswith('MABe22'):\n",
    "            continue\n",
    "        \n",
    "        video_id = row['video_id']\n",
    "        if (submission.video_id == video_id).any():\n",
    "            continue  # Predictions exist, skipping\n",
    "        \n",
    "        if type(row.behaviors_labeled) != str:\n",
    "            continue\n",
    "\n",
    "        print(f\"Video {video_id} has no predictions.\")\n",
    "        \n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "        vid = pd.read_parquet(path)\n",
    "    \n",
    "        vid_behaviors = json.loads(row['behaviors_labeled'])\n",
    "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
    "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n",
    "    \n",
    "        start_frame = vid.video_frame.min()\n",
    "        stop_frame = vid.video_frame.max() + 1\n",
    "    \n",
    "        # Group by agent + target，均匀分配动作帧\n",
    "        for (agent, target), actions in vid_behaviors.groupby(['agent', 'target']):\n",
    "            batch_length = int(np.ceil((stop_frame - start_frame) / len(actions)))\n",
    "            for i, (_, action_row) in enumerate(actions.iterrows()):\n",
    "                batch_start = start_frame + i * batch_length\n",
    "                batch_stop = min(batch_start + batch_length, stop_frame)\n",
    "                s_list.append((video_id, agent, target, action_row['action'], batch_start, batch_stop))\n",
    "\n",
    "    if len(s_list) > 0:\n",
    "        # New filled rows，start_frame/stop_frame 本身是整数，无需转换\n",
    "        submission = pd.concat([\n",
    "            submission,\n",
    "            pd.DataFrame(s_list, columns=['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame'])\n",
    "        ])\n",
    "        print(\"ERROR: Filled empty videos\")\n",
    "\n",
    "    submission = submission.reset_index(drop=True)\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53bd418",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:18.022041Z",
     "iopub.status.busy": "2025-12-15T17:37:18.021467Z",
     "iopub.status.idle": "2025-12-15T17:37:18.028660Z",
     "shell.execute_reply": "2025-12-15T17:37:18.027960Z"
    },
    "papermill": {
     "duration": 0.013443,
     "end_time": "2025-12-15T17:37:18.029716",
     "exception": false,
     "start_time": "2025-12-15T17:37:18.016273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_multiclass(pred, meta, thresholds):\n",
    "    ama = np.argmax(pred.values, axis=1)\n",
    "    max_proba = pred.max(axis=1).values\n",
    "\n",
    "    threshold_array = np.array([thresholds.get(col, 0.27) for col in pred.columns])\n",
    "    action_thresholds = threshold_array[ama]\n",
    "\n",
    "    ama = np.where(max_proba >= action_thresholds, ama, -1)\n",
    "    ama = pd.Series(ama, index=meta.video_frame)\n",
    "    \n",
    "    changes_mask = (ama != ama.shift(1)).values\n",
    "    ama_changes = ama[changes_mask]\n",
    "    meta_changes = meta[changes_mask]\n",
    "    \n",
    "    mask = ama_changes.values >= 0\n",
    "    mask[-1] = False\n",
    "    \n",
    "    submission_part = pd.DataFrame({\n",
    "        'video_id': meta_changes['video_id'][mask].values,\n",
    "        'agent_id': meta_changes['agent_id'][mask].values,\n",
    "        'target_id': meta_changes['target_id'][mask].values,\n",
    "        'action': pred.columns[ama_changes[mask].values],\n",
    "        'start_frame': ama_changes.index[mask],\n",
    "        'stop_frame': ama_changes.index[1:][mask[:-1]]\n",
    "    })\n",
    "    \n",
    "    stop_video_id = meta_changes['video_id'][1:][mask[:-1]].values\n",
    "    stop_agent_id = meta_changes['agent_id'][1:][mask[:-1]].values\n",
    "    stop_target_id = meta_changes['target_id'][1:][mask[:-1]].values\n",
    "    for i in range(len(submission_part)):\n",
    "        video_id = submission_part.video_id.iloc[i]\n",
    "        agent_id = submission_part.agent_id.iloc[i]\n",
    "        target_id = submission_part.target_id.iloc[i]\n",
    "        if stop_video_id[i] != video_id or stop_agent_id[i] != agent_id or stop_target_id[i] != target_id:\n",
    "            new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n",
    "            submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n",
    "\n",
    "    return submission_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b29df7d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:18.039156Z",
     "iopub.status.busy": "2025-12-15T17:37:18.038784Z",
     "iopub.status.idle": "2025-12-15T17:37:18.043015Z",
     "shell.execute_reply": "2025-12-15T17:37:18.042345Z"
    },
    "papermill": {
     "duration": 0.010228,
     "end_time": "2025-12-15T17:37:18.044047",
     "exception": false,
     "start_time": "2025-12-15T17:37:18.033819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tune_threshold(oof_action, y_action):\n",
    "    def objective(trial):\n",
    "        threshold = trial.suggest_float(\"threshold\", 0, 1, step=0.01)\n",
    "        return f1_score(y_action, (oof_action >= threshold), zero_division=0)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=1000, n_jobs=-1)\n",
    "    return study.best_params[\"threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f305635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:18.053404Z",
     "iopub.status.busy": "2025-12-15T17:37:18.053144Z",
     "iopub.status.idle": "2025-12-15T17:37:18.062485Z",
     "shell.execute_reply": "2025-12-15T17:37:18.061787Z"
    },
    "papermill": {
     "duration": 0.015253,
     "end_time": "2025-12-15T17:37:18.063605",
     "exception": false,
     "start_time": "2025-12-15T17:37:18.048352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_validate_classifier_xgb(X, label, meta, body_parts_tracked_str, section):\n",
    "    \"\"\"\n",
    "    Uses XGBoost for training and cross-validation.\n",
    "    \"\"\"\n",
    "    oof = pd.DataFrame(index=meta.video_frame)\n",
    "    f1_list = []\n",
    "    submission_list = []\n",
    "    thresholds = {}\n",
    "\n",
    "    for action in label.columns:\n",
    "        action_mask = ~label[action].isna().values\n",
    "        y_action = label[action][action_mask].values.astype(int)\n",
    "        X_action = X[action_mask]\n",
    "        groups_action = meta.video_id[action_mask]\n",
    "\n",
    "        if len(np.unique(groups_action)) < 2:\n",
    "            continue\n",
    "\n",
    "        if not (y_action == 0).all():\n",
    "            try:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings('ignore')\n",
    "\n",
    "                    # Use GroupKFold\n",
    "                    cv = GroupKFold(n_splits=min(2, len(np.unique(groups_action))))\n",
    "                    oof_action = np.zeros(len(y_action))\n",
    "                    preds = []\n",
    "\n",
    "                    for train_idx, valid_idx in cv.split(X_action, y_action, groups_action):\n",
    "                        model = XGBClassifier(**CFG.xgb_params)\n",
    "                        model.fit(\n",
    "                            X_action.iloc[train_idx], y_action[train_idx],\n",
    "                            eval_set=[(X_action.iloc[valid_idx], y_action[valid_idx])]\n",
    "                        )\n",
    "\n",
    "                        # Feature Importance\n",
    "                        importances = pd.DataFrame({\n",
    "                            'feature': X_action.columns,\n",
    "                            'importance': model.feature_importances_\n",
    "                        }).sort_values('importance', ascending=False)\n",
    "                        # print(f\"\\n[Fold {len(preds)+1}] Top 20 Feature Importance:\")\n",
    "                        # print(importances.head(20))\n",
    "\n",
    "                        oof_action[valid_idx] = model.predict_proba(X_action.iloc[valid_idx])[:, 1]\n",
    "                        preds.append(model)\n",
    "\n",
    "                    threshold = tune_threshold(oof_action, y_action)\n",
    "                    thresholds[action] = threshold\n",
    "                    f1 = f1_score(y_action, (oof_action >= threshold), zero_division=0)\n",
    "                    f1_list.append((body_parts_tracked_str, action, f1))\n",
    "                    print(f\"\\tF1: {f1:.4f} ({threshold:.2f}) Section: {section} Action: {action}\")\n",
    "\n",
    "                    model_dir = f\"{CFG.model_path}/{CFG.model_name}/{section}/{action}\"\n",
    "                    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "                    joblib.dump(preds, f\"{model_dir}/xgb_trainer.pkl\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\tTraining failed: {e}\")\n",
    "                oof_action = np.zeros(len(y_action))\n",
    "        else:\n",
    "            oof_action = np.zeros(len(y_action))\n",
    "            print(f\"\\tF1: 0.0000 (0.00) Section: {section} Action: {action}\")\n",
    "\n",
    "        oof_column = np.zeros(len(label))\n",
    "        oof_column[action_mask] = oof_action\n",
    "        oof[action] = oof_column\n",
    "\n",
    "        del oof_action, action_mask, X_action, y_action, groups_action\n",
    "        gc.collect()\n",
    "\n",
    "    submission_part = predict_multiclass_improved(oof, meta, thresholds)\n",
    "    submission_list.append(submission_part)\n",
    "    print(submission_list)\n",
    "\n",
    "    return submission_list, f1_list, thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24d52067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:18.073522Z",
     "iopub.status.busy": "2025-12-15T17:37:18.073286Z",
     "iopub.status.idle": "2025-12-15T17:37:18.077049Z",
     "shell.execute_reply": "2025-12-15T17:37:18.076400Z"
    },
    "papermill": {
     "duration": 0.010263,
     "end_time": "2025-12-15T17:37:18.078101",
     "exception": false,
     "start_time": "2025-12-15T17:37:18.067838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def submit(body_parts_tracked_str, switch_tr, section, thresholds):\n",
    "#     \"\"\"\n",
    "#     使用LightGBM模型进行预测的submit函数\n",
    "#     \"\"\"\n",
    "#     body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "#     if len(body_parts_tracked) > 5:\n",
    "#         body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n",
    "\n",
    "#     test_subset = test[test.body_parts_tracked == body_parts_tracked_str]\n",
    "#     generator = generate_mouse_data(\n",
    "#         test_subset,\n",
    "#         'test',\n",
    "#         generate_single=(switch_tr == 'single'),\n",
    "#         generate_pair=(switch_tr == 'pair')\n",
    "#     )\n",
    "\n",
    "#     fps_lookup = (\n",
    "#         test_subset[['video_id', 'frames_per_second']]\n",
    "#         .drop_duplicates('video_id')\n",
    "#         .set_index('video_id')['frames_per_second']\n",
    "#         .to_dict()\n",
    "#     )\n",
    "\n",
    "#     submission_list = []\n",
    "\n",
    "#     for switch_te, data_te, meta_te, actions_te in generator:\n",
    "#         assert switch_te == switch_tr\n",
    "#         try:\n",
    "#             fps_i = _fps_from_meta(meta_te, fps_lookup, default_fps=30.0)\n",
    "\n",
    "#             if switch_te == 'single':\n",
    "#                 X_te = transform_single(data_te, body_parts_tracked, fps_i).astype(np.float32)\n",
    "#             else:\n",
    "#                 X_te = transform_pair(data_te, body_parts_tracked, fps_i).astype(np.float32)\n",
    "#             del data_te\n",
    "#             gc.collect()\n",
    "\n",
    "#             pred = pd.DataFrame(index=meta_te.video_frame)\n",
    "\n",
    "#             for action in actions_te:\n",
    "#                 # 加载LightGBM模型\n",
    "#                 files = glob.glob(f\"{CFG.model_path}/{CFG.model_name}/{section}/{action}/lgb_trainer.pkl\")\n",
    "#                 if len(files) == 1:\n",
    "#                     models = joblib.load(files[0])\n",
    "#                     # 多折预测取平均概率\n",
    "#                     prob = np.mean([m.predict_proba(X_te)[:, 1] for m in models], axis=0)\n",
    "#                     pred[action] = prob\n",
    "\n",
    "#                     del models\n",
    "#                     gc.collect()\n",
    "\n",
    "#             del X_te\n",
    "#             gc.collect()\n",
    "\n",
    "#             if pred.shape[1] != 0:\n",
    "#                 # 使用多类概率阈值生成提交\n",
    "#                 submission_part = predict_multiclass(pred, meta_te, thresholds)\n",
    "#                 submission_list.append(submission_part)\n",
    "\n",
    "#         except KeyError:\n",
    "#             del data_te\n",
    "#             gc.collect()\n",
    "\n",
    "#     return submission_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd4e6db8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:18.087654Z",
     "iopub.status.busy": "2025-12-15T17:37:18.087436Z",
     "iopub.status.idle": "2025-12-15T17:37:18.101946Z",
     "shell.execute_reply": "2025-12-15T17:37:18.101249Z"
    },
    "papermill": {
     "duration": 0.020687,
     "end_time": "2025-12-15T17:37:18.103032",
     "exception": false,
     "start_time": "2025-12-15T17:37:18.082345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gc\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import joblib\n",
    "\n",
    "# [NEW] Post-processing: Gap Filling\n",
    "def fill_gaps(binary_preds, max_gap=5):\n",
    "    \"\"\"Fills short gaps (0s) between 1s.\"\"\"\n",
    "    # Convert to int for processing\n",
    "    preds = binary_preds.astype(int)\n",
    "    # Find runs of 0s\n",
    "    # Pad with 1s to handle edge cases\n",
    "    padded = np.concatenate(([1], preds, [1]))\n",
    "    diff = np.diff(padded)\n",
    "    starts = np.where(diff == -1)[0]\n",
    "    stops = np.where(diff == 1)[0]\n",
    "    \n",
    "    for start, stop in zip(starts, stops):\n",
    "        gap_len = stop - start\n",
    "        if gap_len <= max_gap:\n",
    "            preds[start:stop] = 1\n",
    "    return preds\n",
    "\n",
    "# [NEW] Post-processing: Min Duration\n",
    "def remove_short_duration(binary_preds, min_len=5):\n",
    "    \"\"\"Removes short bursts of 1s.\"\"\"\n",
    "    preds = binary_preds.astype(int)\n",
    "    padded = np.concatenate(([0], preds, [0]))\n",
    "    diff = np.diff(padded)\n",
    "    starts = np.where(diff == 1)[0]\n",
    "    stops = np.where(diff == -1)[0]\n",
    "    \n",
    "    for start, stop in zip(starts, stops):\n",
    "        duration = stop - start\n",
    "        if duration <= min_len:\n",
    "            preds[start:stop] = 0\n",
    "    return preds\n",
    "\n",
    "\n",
    "\n",
    "def predict_multiclass_improved(pred, meta, thresholds, min_duration=5, max_gap=5):\n",
    "    \"\"\"\n",
    "    Updated prediction function with Gap Filling and Min Duration filtering.\n",
    "    \"\"\"\n",
    "    if pred.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Ensure meta has correct index\n",
    "    if not all(col in meta.columns for col in ['video_id', 'agent_id', 'target_id', 'video_frame']):\n",
    "        print(f\"\\t    Meta data missing required columns: {meta.columns}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # 1. Apply Thresholds to get Binary Masks per Action\n",
    "    binary_masks = {}\n",
    "    for col in pred.columns:\n",
    "        thresh = thresholds.get(col, 0.27)\n",
    "        mask = (pred[col].values >= thresh).astype(int)\n",
    "        \n",
    "        # [NEW] Apply Post-processing per action\n",
    "        mask = fill_gaps(mask, max_gap=max_gap)\n",
    "        mask = remove_short_duration(mask, min_len=min_duration)\n",
    "        \n",
    "        binary_masks[col] = mask\n",
    "        \n",
    "    # 2. Combine to Multi-class (Argmax)\n",
    "    # We need to handle conflicts. If multiple actions are 1, pick max prob?\n",
    "    # Or just use the processed masks to filter the original probabilities?\n",
    "    # Let's use the processed masks as a hard filter, then argmax on probs.\n",
    "    \n",
    "    valid_mask = np.zeros(len(pred), dtype=bool)\n",
    "    for col, mask in binary_masks.items():\n",
    "        valid_mask |= (mask == 1)\n",
    "        \n",
    "    # If no action is valid, it's background (-1)\n",
    "    # If multiple are valid, pick max prob among them\n",
    "    \n",
    "    ama = np.full(len(pred), -1)\n",
    "    \n",
    "    # Only consider frames where at least one action passed the filters\n",
    "    if np.any(valid_mask):\n",
    "        # Mask out probabilities where binary_mask is 0\n",
    "        masked_probs = pred.copy()\n",
    "        for col in pred.columns:\n",
    "            masked_probs.loc[binary_masks[col] == 0, col] = -1.0\n",
    "            \n",
    "        # Argmax on masked probs\n",
    "        best_idx = np.argmax(masked_probs.values, axis=1)\n",
    "        max_val = np.max(masked_probs.values, axis=1)\n",
    "        \n",
    "        # Assign where max_val > -1 (meaning at least one action was valid)\n",
    "        ama = np.where(max_val > -1.0, best_idx, -1)\n",
    "\n",
    "    # Construct Segments\n",
    "    submission_parts = []\n",
    "    \n",
    "    if len(ama) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    current_action = ama[0]\n",
    "    start_frame = meta.video_frame.iloc[0] if hasattr(meta.video_frame, 'iloc') else meta.video_frame.values[0]\n",
    "    \n",
    "    for i in range(1, len(ama)):\n",
    "        if ama[i] != current_action:\n",
    "            # End of current segment\n",
    "            if current_action >= 0:\n",
    "                try:\n",
    "                    video_id = meta.video_id.iloc[i-1] if hasattr(meta.video_id, 'iloc') else meta.video_id.values[i-1]\n",
    "                    agent_id = meta.agent_id.iloc[i-1] if hasattr(meta.agent_id, 'iloc') else meta.agent_id.values[i-1]\n",
    "                    target_id = meta.target_id.iloc[i-1] if hasattr(meta.target_id, 'iloc') else meta.target_id.values[i-1]\n",
    "                    stop_frame = meta.video_frame.iloc[i-1] + 1 if hasattr(meta.video_frame, 'iloc') else meta.video_frame.values[i-1] + 1\n",
    "                    \n",
    "                    submission_parts.append({\n",
    "                        'video_id': video_id,\n",
    "                        'agent_id': agent_id,\n",
    "                        'target_id': target_id,\n",
    "                        'action': pred.columns[current_action],\n",
    "                        'start_frame': start_frame,\n",
    "                        'stop_frame': stop_frame\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"\\t      Failed to create submission segment: {e}\")\n",
    "            \n",
    "            # Start new segment\n",
    "            current_action = ama[i]\n",
    "            start_frame = meta.video_frame.iloc[i] if hasattr(meta.video_frame, 'iloc') else meta.video_frame.values[i]\n",
    "            \n",
    "    # Last segment\n",
    "    if current_action >= 0:\n",
    "        try:\n",
    "            video_id = meta.video_id.iloc[-1] if hasattr(meta.video_id, 'iloc') else meta.video_id.values[-1]\n",
    "            agent_id = meta.agent_id.iloc[-1] if hasattr(meta.agent_id, 'iloc') else meta.agent_id.values[-1]\n",
    "            target_id = meta.target_id.iloc[-1] if hasattr(meta.target_id, 'iloc') else meta.target_id.values[-1]\n",
    "            stop_frame = meta.video_frame.iloc[-1] + 1 if hasattr(meta.video_frame, 'iloc') else meta.video_frame.values[-1] + 1\n",
    "            \n",
    "            submission_parts.append({\n",
    "                'video_id': video_id,\n",
    "                'agent_id': agent_id,\n",
    "                'target_id': target_id,\n",
    "                'action': pred.columns[current_action],\n",
    "                'start_frame': start_frame,\n",
    "                'stop_frame': stop_frame\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"\\t      Failed to create last submission segment: {e}\")\n",
    "            \n",
    "    return pd.DataFrame(submission_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e346d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:18.113747Z",
     "iopub.status.busy": "2025-12-15T17:37:18.113287Z",
     "iopub.status.idle": "2025-12-15T17:37:18.127123Z",
     "shell.execute_reply": "2025-12-15T17:37:18.126435Z"
    },
    "papermill": {
     "duration": 0.021094,
     "end_time": "2025-12-15T17:37:18.128449",
     "exception": false,
     "start_time": "2025-12-15T17:37:18.107355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def submit_xgb(body_parts_tracked_str, switch_tr, section, thresholds, max_workers=2):\n",
    "    \"\"\"\n",
    "    Submit function using XGBoost models.\n",
    "    \"\"\"\n",
    "    body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "    if len(body_parts_tracked) > 5:\n",
    "        body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n",
    "\n",
    "    test_subset = test[test.body_parts_tracked == body_parts_tracked_str]\n",
    "    \n",
    "    print(f\"\\tTest subset size: {len(test_subset)}\")\n",
    "    \n",
    "    if len(test_subset) == 0:\n",
    "        return []\n",
    "    \n",
    "    fps_lookup = (\n",
    "        test_subset[['video_id', 'frames_per_second']]\n",
    "        .drop_duplicates('video_id')\n",
    "        .set_index('video_id')['frames_per_second']\n",
    "        .to_dict()\n",
    "    )\n",
    "    \n",
    "    models_cache = {}\n",
    "    all_actions = set()\n",
    "    \n",
    "    for _, row in test_subset.iterrows():\n",
    "        if type(row.behaviors_labeled) == str:\n",
    "            try:\n",
    "                behaviors = json.loads(row.behaviors_labeled)\n",
    "                for behavior in behaviors:\n",
    "                    if isinstance(behavior, str) and ',' in behavior:\n",
    "                        parts = behavior.split(',')\n",
    "                        if len(parts) >= 3:\n",
    "                            action = parts[2]\n",
    "                        else:\n",
    "                            action = behavior\n",
    "                    else:\n",
    "                        action = str(behavior)\n",
    "                    all_actions.add(action)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    for action in all_actions:\n",
    "        try:\n",
    "            model_path_pattern = f\"{CFG.model_path}/{CFG.model_name}/{section}/{action}/xgb_trainer.pkl\"\n",
    "            model_files = glob.glob(model_path_pattern)\n",
    "            \n",
    "            if model_files:\n",
    "                models = joblib.load(model_files[0])\n",
    "                models_cache[action] = models\n",
    "                print(f\"\\t✓ Loaded model: {action}\")\n",
    "            else:\n",
    "                print(f\"\\t✗ Model not found: {action}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\t✗ Failed to load model {action}: {e}\")\n",
    "    \n",
    "    def process_single_video(row):\n",
    "        try:\n",
    "            video_data = pd.DataFrame([row])\n",
    "            generator = generate_mouse_data(\n",
    "                video_data,\n",
    "                'test',\n",
    "                traintest_directory=CFG.test_tracking_path,\n",
    "                generate_single=(switch_tr == 'single'),\n",
    "                generate_pair=(switch_tr == 'pair')\n",
    "            )\n",
    "            \n",
    "            video_submissions = []\n",
    "            \n",
    "            for switch_te, data_te, meta_te, actions_te in generator:\n",
    "                try:\n",
    "                    fps_i = _fps_from_meta(meta_te, fps_lookup, default_fps=30.0)\n",
    "                    \n",
    "                    if switch_te == 'single':\n",
    "                        X_te = transform_single(data_te, body_parts_tracked, fps_i).astype(np.float32)\n",
    "                    else:\n",
    "                        X_te = transform_pair(data_te, body_parts_tracked, fps_i).astype(np.float32)\n",
    "                    \n",
    "                    del data_te\n",
    "                    gc.collect()\n",
    "                    \n",
    "                    if X_te.shape[0] == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    pred = pd.DataFrame(index=meta_te.video_frame)\n",
    "                    \n",
    "                    for action in actions_te:\n",
    "                        if action in models_cache:\n",
    "                            try:\n",
    "                                models = models_cache[action]\n",
    "                                probas = []\n",
    "                                for model in models:\n",
    "                                    prob = model.predict_proba(X_te)[:, 1]\n",
    "                                    probas.append(prob)\n",
    "                                \n",
    "                                if probas:\n",
    "                                    mean_prob = np.mean(probas, axis=0)\n",
    "                                    pred[action] = mean_prob\n",
    "                            except Exception as e:\n",
    "                                continue\n",
    "                    \n",
    "                    del X_te\n",
    "                    gc.collect()\n",
    "                    \n",
    "                    if not pred.empty and pred.shape[1] > 0:\n",
    "                        submission_part = predict_multiclass_improved(pred, meta_te, thresholds)\n",
    "                        if len(submission_part) > 0:\n",
    "                            video_submissions.append(submission_part)\n",
    "                    \n",
    "                    del pred\n",
    "                    gc.collect()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            return video_submissions\n",
    "            \n",
    "        except Exception as e:\n",
    "            return []\n",
    "    \n",
    "    submission_list = []\n",
    "    \n",
    "    for idx, row in test_subset.iterrows():\n",
    "        result = process_single_video(row)\n",
    "        if result:\n",
    "            submission_list.extend(result)\n",
    "        if idx % 5 == 0:\n",
    "            gc.collect()\n",
    "    \n",
    "    del models_cache\n",
    "    gc.collect()\n",
    "    \n",
    "    return submission_list\n",
    "\n",
    "submit = submit_xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c5ec0",
   "metadata": {
    "papermill": {
     "duration": 0.004206,
     "end_time": "2025-12-15T17:37:18.137212",
     "exception": false,
     "start_time": "2025-12-15T17:37:18.133006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b081a432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:18.147042Z",
     "iopub.status.busy": "2025-12-15T17:37:18.146354Z",
     "iopub.status.idle": "2025-12-15T17:37:18.152637Z",
     "shell.execute_reply": "2025-12-15T17:37:18.152055Z"
    },
    "papermill": {
     "duration": 0.012259,
     "end_time": "2025-12-15T17:37:18.153702",
     "exception": false,
     "start_time": "2025-12-15T17:37:18.141443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载阈值文件: /kaggle/input/model-weights/models/xgboost/thresholds.pkl\n"
     ]
    }
   ],
   "source": [
    "if CFG.mode == \"validate\":\n",
    "    thresholds = {\n",
    "        \"single\": {},\n",
    "        \"pair\": {}\n",
    "    }\n",
    "else:\n",
    "    try:\n",
    "        #################################################################\n",
    "        thresholds_path = f\"{CFG.model_path}/{CFG.model_name}/thresholds.pkl\" #############\n",
    "        thresholds = joblib.load(thresholds_path)\n",
    "        print(f\"成功加载阈值文件: {thresholds_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"加载阈值文件失败: {e}\") \n",
    "        # 尝试其他可能的路径\n",
    "        try:\n",
    "            ###########################################################################################\n",
    "            thresholds_path = f\"/kaggle/input/{CFG.model_path}/{CFG.model_name}/thresholds.pkl\"\n",
    "            #################################################################\n",
    "            thresholds = joblib.load(thresholds_path)\n",
    "            print(f\"成功加载阈值文件: {thresholds_path}\")\n",
    "        except Exception as e2:\n",
    "            print(f\"再次加载阈值文件失败: {e2}\")\n",
    "            thresholds = {\n",
    "                \"single\": {\"default\": 0.5},\n",
    "                \"pair\": {\"default\": 0.5}\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe26a16d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:37:18.163837Z",
     "iopub.status.busy": "2025-12-15T17:37:18.163611Z",
     "iopub.status.idle": "2025-12-15T17:57:42.222344Z",
     "shell.execute_reply": "2025-12-15T17:57:42.221578Z"
    },
    "papermill": {
     "duration": 1224.065394,
     "end_time": "2025-12-15T17:57:42.223619",
     "exception": false,
     "start_time": "2025-12-15T17:37:18.158225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright', 'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright', 'lateral_left', 'lateral_right', 'neck', 'nose', 'tail_base', 'tail_midpoint', 'tail_tip']\n",
      "\n",
      "\tTest subset size: 1\n",
      "\t✓ Loaded model: attack\n",
      "\t✓ Loaded model: chaseattack\n",
      "\t✓ Loaded model: avoid\n",
      "\t✓ Loaded model: submit\n",
      "\t✓ Loaded model: chase\n",
      "\t✓ Loaded model: approach\n",
      "\t✓ Loaded model: rear\n",
      "[     video_id agent_id target_id action  start_frame  stop_frame\n",
      "0   438887472   mouse1      self   rear          192         203\n",
      "1   438887472   mouse1      self   rear          229         271\n",
      "2   438887472   mouse1      self   rear         1263        1270\n",
      "3   438887472   mouse1      self   rear         1320        1334\n",
      "4   438887472   mouse1      self   rear         1419        1431\n",
      "5   438887472   mouse1      self   rear         1542        1555\n",
      "6   438887472   mouse1      self   rear         2107        2143\n",
      "7   438887472   mouse1      self   rear         2157        2198\n",
      "8   438887472   mouse1      self   rear         2207        2233\n",
      "9   438887472   mouse1      self   rear         2333        2427\n",
      "10  438887472   mouse1      self   rear         2683        2722\n",
      "11  438887472   mouse1      self   rear         3061        3122\n",
      "12  438887472   mouse1      self   rear         4303        4390\n",
      "13  438887472   mouse1      self   rear         6398        6412\n",
      "14  438887472   mouse1      self   rear         6426        6469\n",
      "15  438887472   mouse1      self   rear         8850        9084\n",
      "16  438887472   mouse1      self   rear        11510       11553\n",
      "17  438887472   mouse1      self   rear        14488       14548,       video_id agent_id target_id action  start_frame  stop_frame\n",
      "0    438887472   mouse2      self   rear          371         382\n",
      "1    438887472   mouse2      self   rear          452         593\n",
      "2    438887472   mouse2      self   rear          660         670\n",
      "3    438887472   mouse2      self   rear          762         898\n",
      "4    438887472   mouse2      self   rear         1212        1347\n",
      "..         ...      ...       ...    ...          ...         ...\n",
      "120  438887472   mouse2      self   rear        17096       17675\n",
      "121  438887472   mouse2      self   rear        17778       17928\n",
      "122  438887472   mouse2      self   rear        18004       18014\n",
      "123  438887472   mouse2      self   rear        18038       18139\n",
      "124  438887472   mouse2      self   rear        18168       18274\n",
      "\n",
      "[125 rows x 6 columns],       video_id agent_id target_id action  start_frame  stop_frame\n",
      "0    438887472   mouse3      self   rear           20          81\n",
      "1    438887472   mouse3      self   rear          341         373\n",
      "2    438887472   mouse3      self   rear          439         459\n",
      "3    438887472   mouse3      self   rear          478         489\n",
      "4    438887472   mouse3      self   rear          509         515\n",
      "..         ...      ...       ...    ...          ...         ...\n",
      "124  438887472   mouse3      self   rear        18226       18253\n",
      "125  438887472   mouse3      self   rear        18272       18295\n",
      "126  438887472   mouse3      self   rear        18316       18332\n",
      "127  438887472   mouse3      self   rear        18344       18350\n",
      "128  438887472   mouse3      self   rear        18417       18423\n",
      "\n",
      "[129 rows x 6 columns]]\n",
      "\tTest subset size: 1\n",
      "\t✓ Loaded model: attack\n",
      "\t✓ Loaded model: chaseattack\n",
      "\t✓ Loaded model: avoid\n",
      "\t✓ Loaded model: submit\n",
      "\t✓ Loaded model: chase\n",
      "\t✓ Loaded model: approach\n",
      "\t✓ Loaded model: rear\n",
      "[     video_id agent_id target_id    action  start_frame  stop_frame\n",
      "0   438887472   mouse1    mouse2  approach          711         717\n",
      "1   438887472   mouse1    mouse2    submit          726         746\n",
      "2   438887472   mouse1    mouse2    attack          854         876\n",
      "3   438887472   mouse1    mouse2    submit          887         935\n",
      "4   438887472   mouse1    mouse2    submit          941         947\n",
      "5   438887472   mouse1    mouse2     chase         1052        1084\n",
      "6   438887472   mouse1    mouse2    attack         1084        1085\n",
      "7   438887472   mouse1    mouse2     chase         1085        1086\n",
      "8   438887472   mouse1    mouse2    attack         1086        1093\n",
      "9   438887472   mouse1    mouse2     chase         1093        1094\n",
      "10  438887472   mouse1    mouse2    attack         1094        1099\n",
      "11  438887472   mouse1    mouse2    submit         1099        1100\n",
      "12  438887472   mouse1    mouse2    attack         1100        1101\n",
      "13  438887472   mouse1    mouse2     avoid         1115        1132\n",
      "14  438887472   mouse1    mouse2     avoid         1441        1467\n",
      "15  438887472   mouse1    mouse2  approach         3099        3131\n",
      "16  438887472   mouse1    mouse2    submit         3131        3151\n",
      "17  438887472   mouse1    mouse2  approach         3151        3152\n",
      "18  438887472   mouse1    mouse2    submit         3152        3153\n",
      "19  438887472   mouse1    mouse2  approach         3153        3154\n",
      "20  438887472   mouse1    mouse2    submit         3154        3162\n",
      "21  438887472   mouse1    mouse2  approach         8844        8861\n",
      "22  438887472   mouse1    mouse2     avoid         8871        8895\n",
      "23  438887472   mouse1    mouse2    submit         8900        8910\n",
      "24  438887472   mouse1    mouse2    submit        12145       12165\n",
      "25  438887472   mouse1    mouse2    submit        12171       12204\n",
      "26  438887472   mouse1    mouse2    submit        12432       12445\n",
      "27  438887472   mouse1    mouse2    submit        12452       12459\n",
      "28  438887472   mouse1    mouse2    submit        12481       12556\n",
      "29  438887472   mouse1    mouse2     avoid        12556       12568\n",
      "30  438887472   mouse1    mouse2    submit        12568       12569\n",
      "31  438887472   mouse1    mouse2     avoid        12569       12579\n",
      "32  438887472   mouse1    mouse2    submit        12579       12580\n",
      "33  438887472   mouse1    mouse2     avoid        12580       12589\n",
      "34  438887472   mouse1    mouse2    submit        12589       12609\n",
      "35  438887472   mouse1    mouse2     chase        14289       14307\n",
      "36  438887472   mouse1    mouse2     chase        14314       14365\n",
      "37  438887472   mouse1    mouse2     chase        14381       14484\n",
      "38  438887472   mouse1    mouse2     chase        14550       14737\n",
      "39  438887472   mouse1    mouse2  approach        14801       14812\n",
      "40  438887472   mouse1    mouse2     avoid        14875       14903\n",
      "41  438887472   mouse1    mouse2    submit        14910       14921\n",
      "42  438887472   mouse1    mouse2     avoid        15073       15081\n",
      "43  438887472   mouse1    mouse2  approach        16603       16618\n",
      "44  438887472   mouse1    mouse2     avoid        16635       16651\n",
      "45  438887472   mouse1    mouse2    submit        16651       16652\n",
      "46  438887472   mouse1    mouse2     avoid        16652       16653\n",
      "47  438887472   mouse1    mouse2    submit        16653       16656\n",
      "48  438887472   mouse1    mouse2     avoid        16656       16657\n",
      "49  438887472   mouse1    mouse2    submit        16657       16658\n",
      "50  438887472   mouse1    mouse2     avoid        16658       16659\n",
      "51  438887472   mouse1    mouse2    submit        16659       16664\n",
      "52  438887472   mouse1    mouse2  approach        17939       17955\n",
      "53  438887472   mouse1    mouse2     avoid        17955       17968\n",
      "54  438887472   mouse1    mouse2    submit        17968       17978\n",
      "55  438887472   mouse1    mouse2     avoid        17978       17979\n",
      "56  438887472   mouse1    mouse2    submit        17979       17993,      video_id agent_id target_id  action  start_frame  stop_frame\n",
      "0   438887472   mouse1    mouse3  submit            0          16\n",
      "1   438887472   mouse1    mouse3  submit           74          93\n",
      "2   438887472   mouse1    mouse3  submit          146         155\n",
      "3   438887472   mouse1    mouse3  submit          162         181\n",
      "4   438887472   mouse1    mouse3  submit          191         203\n",
      "..        ...      ...       ...     ...          ...         ...\n",
      "76  438887472   mouse1    mouse3  submit        12248       12257\n",
      "77  438887472   mouse1    mouse3  submit        12271       12306\n",
      "78  438887472   mouse1    mouse3  submit        13006       13025\n",
      "79  438887472   mouse1    mouse3  submit        13498       13524\n",
      "80  438887472   mouse1    mouse3   chase        14489       14510\n",
      "\n",
      "[81 rows x 6 columns],      video_id agent_id target_id    action  start_frame  stop_frame\n",
      "0   438887472   mouse2    mouse1     avoid          103         119\n",
      "1   438887472   mouse2    mouse1     avoid          153         174\n",
      "2   438887472   mouse2    mouse1     avoid          188         218\n",
      "3   438887472   mouse2    mouse1  approach          680         771\n",
      "4   438887472   mouse2    mouse1    submit          851         887\n",
      "..        ...      ...       ...       ...          ...         ...\n",
      "67  438887472   mouse2    mouse1     avoid        16620       16704\n",
      "68  438887472   mouse2    mouse1     avoid        16875       16896\n",
      "69  438887472   mouse2    mouse1     avoid        17058       17076\n",
      "70  438887472   mouse2    mouse1  approach        17928       17959\n",
      "71  438887472   mouse2    mouse1     avoid        17959       18023\n",
      "\n",
      "[72 rows x 6 columns],       video_id agent_id target_id    action  start_frame  stop_frame\n",
      "0    438887472   mouse2    mouse3     avoid          104         110\n",
      "1    438887472   mouse2    mouse3     avoid          140         216\n",
      "2    438887472   mouse2    mouse3  approach          261         302\n",
      "3    438887472   mouse2    mouse3     avoid          302         315\n",
      "4    438887472   mouse2    mouse3  approach          315         332\n",
      "..         ...      ...       ...       ...          ...         ...\n",
      "171  438887472   mouse2    mouse3    attack        18126       18140\n",
      "172  438887472   mouse2    mouse3     chase        18140       18141\n",
      "173  438887472   mouse2    mouse3    attack        18141       18184\n",
      "174  438887472   mouse2    mouse3    attack        18213       18257\n",
      "175  438887472   mouse2    mouse3     avoid        18301       18423\n",
      "\n",
      "[176 rows x 6 columns],       video_id agent_id target_id    action  start_frame  stop_frame\n",
      "0    438887472   mouse3    mouse1     avoid            0          10\n",
      "1    438887472   mouse3    mouse1  approach           10          12\n",
      "2    438887472   mouse3    mouse1     avoid           12          21\n",
      "3    438887472   mouse3    mouse1  approach           21          22\n",
      "4    438887472   mouse3    mouse1     avoid           22          38\n",
      "..         ...      ...       ...       ...          ...         ...\n",
      "96   438887472   mouse3    mouse1     avoid        14277       14327\n",
      "97   438887472   mouse3    mouse1     avoid        14347       14355\n",
      "98   438887472   mouse3    mouse1     chase        14496       14502\n",
      "99   438887472   mouse3    mouse1     avoid        14651       14684\n",
      "100  438887472   mouse3    mouse1     avoid        17531       17537\n",
      "\n",
      "[101 rows x 6 columns],       video_id agent_id target_id    action  start_frame  stop_frame\n",
      "0    438887472   mouse3    mouse2     avoid          121         130\n",
      "1    438887472   mouse3    mouse2     avoid          158         164\n",
      "2    438887472   mouse3    mouse2  approach          271         301\n",
      "3    438887472   mouse3    mouse2  approach          308         315\n",
      "4    438887472   mouse3    mouse2     avoid          373         438\n",
      "..         ...      ...       ...       ...          ...         ...\n",
      "198  438887472   mouse3    mouse2  approach        18365       18367\n",
      "199  438887472   mouse3    mouse2     chase        18367       18368\n",
      "200  438887472   mouse3    mouse2  approach        18368       18370\n",
      "201  438887472   mouse3    mouse2     chase        18370       18385\n",
      "202  438887472   mouse3    mouse2  approach        18385       18423\n",
      "\n",
      "[203 rows x 6 columns]]\n",
      "\n",
      "2/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'hip_left', 'hip_right', 'lateral_left', 'lateral_right', 'nose', 'spine_1', 'spine_2', 'tail_base', 'tail_middle_1', 'tail_middle_2', 'tail_tip']\n",
      "\n",
      "\tTest subset size: 0\n",
      "\tTest subset size: 0\n",
      "\n",
      "3/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'lateral_left', 'lateral_right', 'neck', 'nose', 'tail_base', 'tail_midpoint', 'tail_tip']\n",
      "\n",
      "\tTest subset size: 0\n",
      "\tTest subset size: 0\n",
      "\n",
      "4/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'lateral_left', 'lateral_right', 'nose', 'tail_base', 'tail_tip']\n",
      "\n",
      "\tTest subset size: 0\n",
      "\n",
      "5/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'lateral_left', 'lateral_right', 'nose', 'tail_base']\n",
      "\n",
      "\tTest subset size: 0\n",
      "\n",
      "6/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'nose', 'tail_base']\n",
      "\n",
      "\tTest subset size: 0\n",
      "\tTest subset size: 0\n",
      "\n",
      "7/9 Processing videos with: ['ear_left', 'ear_right', 'head', 'tail_base']\n",
      "\n",
      "\tTest subset size: 0\n",
      "\tTest subset size: 0\n",
      "\n",
      "8/9 Processing videos with: ['ear_left', 'ear_right', 'hip_left', 'hip_right', 'neck', 'nose', 'tail_base']\n",
      "\n",
      "\tTest subset size: 0\n",
      "\tTest subset size: 0\n",
      "\n",
      "9/9 Processing videos with: ['ear_left', 'ear_right', 'nose', 'tail_base', 'tail_tip']\n",
      "\n",
      "\tTest subset size: 0\n",
      "\tTest subset size: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f1_list = []\n",
    "submission_list = []\n",
    "\n",
    "for section in range(1, len(body_parts_tracked_list)):\n",
    "    body_parts_tracked_str = body_parts_tracked_list[section]\n",
    "    try:\n",
    "        body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "        print(f\"{section}/{len(body_parts_tracked_list)-1} Processing videos with: {body_parts_tracked}\\n\")\n",
    "        \n",
    "        if len(body_parts_tracked) > 5:\n",
    "            body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n",
    "    \n",
    "        train_subset = train[train.body_parts_tracked == body_parts_tracked_str]\n",
    "\n",
    "        _fps_lookup = (\n",
    "            train_subset[['video_id', 'frames_per_second']]\n",
    "            .drop_duplicates('video_id')\n",
    "            .set_index('video_id')['frames_per_second']\n",
    "            .to_dict()\n",
    "        )\n",
    "        \n",
    "        single_mouse_list = []\n",
    "        single_mouse_label_list = []\n",
    "        single_mouse_meta_list = []\n",
    "        \n",
    "        mouse_pair_list = []\n",
    "        mouse_pair_label_list = []\n",
    "        mouse_pair_meta_list = []\n",
    "    \n",
    "        for switch, data, meta, label in generate_mouse_data(train_subset, 'train'):\n",
    "            if switch == 'single':\n",
    "                single_mouse_list.append(data)\n",
    "                single_mouse_meta_list.append(meta)\n",
    "                single_mouse_label_list.append(label)\n",
    "            else:\n",
    "                mouse_pair_list.append(data)\n",
    "                mouse_pair_meta_list.append(meta)\n",
    "                mouse_pair_label_list.append(label)\n",
    "            \n",
    "            del data, meta, label\n",
    "        gc.collect()\n",
    "    \n",
    "    \n",
    "        if len(single_mouse_list) > 0:\n",
    "            single_feats_parts = []\n",
    "            for data_i, meta_i in zip(single_mouse_list, single_mouse_meta_list):\n",
    "                fps_i = _fps_from_meta(meta_i, _fps_lookup, default_fps=30.0)\n",
    "                X_i = transform_single(data_i, body_parts_tracked, fps_i).astype(np.float32)\n",
    "                single_feats_parts.append(X_i)\n",
    "                del X_i, fps_i\n",
    "            gc.collect()\n",
    "\n",
    "            X_tr = pd.concat(single_feats_parts, axis=0, ignore_index=True)\n",
    "            single_mouse_label = pd.concat(single_mouse_label_list, axis=0, ignore_index=True)\n",
    "            single_mouse_meta = pd.concat(single_mouse_meta_list, axis=0, ignore_index=True)\n",
    "            \n",
    "            del single_feats_parts, single_mouse_list, single_mouse_label_list, single_mouse_meta_list\n",
    "            gc.collect()\n",
    "\n",
    "            if CFG.mode == 'validate':\n",
    "                temp_submission_list, temp_f1_list, temp_thresholds = cross_validate_classifier_xgb(X_tr, single_mouse_label, single_mouse_meta, body_parts_tracked_str, section)\n",
    "                \n",
    "                if f\"{section}\" not in thresholds[\"single\"].keys():\n",
    "                    thresholds[\"single\"][f\"{section}\"] = {}\n",
    "                for k, v in temp_thresholds.items():\n",
    "                    thresholds[\"single\"][f\"{section}\"][k] = v                  \n",
    "                \n",
    "                f1_list.extend(temp_f1_list)\n",
    "                submission_list.extend(temp_submission_list)\n",
    "                \n",
    "                del temp_submission_list, temp_f1_list, temp_thresholds, X_tr\n",
    "                gc.collect()\n",
    "            else:\n",
    "                temp_submission_list = submit(body_parts_tracked_str, 'single', section, thresholds[\"single\"][f\"{section}\"])\n",
    "                submission_list.extend(temp_submission_list)\n",
    "                \n",
    "                del temp_submission_list, X_tr\n",
    "                gc.collect()\n",
    "                \n",
    "        if len(mouse_pair_list) > 0:\n",
    "            pair_feats_parts = []\n",
    "            for data_i, meta_i in zip(mouse_pair_list, mouse_pair_meta_list):\n",
    "                fps_i = _fps_from_meta(meta_i, _fps_lookup, default_fps=30.0)\n",
    "                X_i = transform_pair(data_i, body_parts_tracked, fps_i).astype(np.float32)\n",
    "                pair_feats_parts.append(X_i)\n",
    "                del X_i, fps_i\n",
    "            gc.collect()\n",
    "\n",
    "            X_tr = pd.concat(pair_feats_parts, axis=0, ignore_index=True)\n",
    "            mouse_pair_label = pd.concat(mouse_pair_label_list, axis=0, ignore_index=True)\n",
    "            mouse_pair_meta = pd.concat(mouse_pair_meta_list, axis=0, ignore_index=True)\n",
    "            \n",
    "            del pair_feats_parts, mouse_pair_list, mouse_pair_label_list, mouse_pair_meta_list\n",
    "            gc.collect()\n",
    "\n",
    "            if CFG.mode == 'validate':\n",
    "                temp_submission_list, temp_f1_list, temp_thresholds = cross_validate_classifier_xgb(X_tr, mouse_pair_label, mouse_pair_meta, body_parts_tracked_str, section)\n",
    "\n",
    "                if f\"{section}\" not in thresholds[\"pair\"].keys():\n",
    "                    thresholds[\"pair\"][f\"{section}\"] = {}\n",
    "                for k, v in temp_thresholds.items():\n",
    "                    thresholds[\"pair\"][f\"{section}\"][k] = v  \n",
    "                    \n",
    "                f1_list.extend(temp_f1_list)\n",
    "                submission_list.extend(temp_submission_list)\n",
    "                \n",
    "                del temp_submission_list, temp_f1_list, temp_thresholds, X_tr\n",
    "                gc.collect()\n",
    "            else:\n",
    "                temp_submission_list = submit(body_parts_tracked_str, 'pair', section, thresholds[\"pair\"][f\"{section}\"])\n",
    "                \n",
    "                submission_list.extend(temp_submission_list)\n",
    "                del temp_submission_list, X_tr\n",
    "                gc.collect()\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"\\t{e}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3554977",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:57:42.235606Z",
     "iopub.status.busy": "2025-12-15T17:57:42.235331Z",
     "iopub.status.idle": "2025-12-15T17:57:42.239900Z",
     "shell.execute_reply": "2025-12-15T17:57:42.239192Z"
    },
    "papermill": {
     "duration": 0.011807,
     "end_time": "2025-12-15T17:57:42.240952",
     "exception": false,
     "start_time": "2025-12-15T17:57:42.229145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.mode == 'validate':  \n",
    "    submission = pd.concat(submission_list)\n",
    "    submission_robust = robustify(submission, train, 'train')\n",
    "    print(f\"Competition metric: {score(solution, submission_robust, ''):.4f}\")\n",
    "\n",
    "    f1_df = pd.DataFrame(f1_list, columns=['body_parts_tracked_str', 'action', 'binary F1 score'])\n",
    "    print(f\"Mean F1:            {f1_df['binary F1 score'].mean():.4f}\")\n",
    "  \n",
    "    joblib.dump(thresholds, f\"{CFG.model_name}/thresholds.pkl\")\n",
    "    joblib.dump(f1_df, f\"{CFG.model_name}/scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f304e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:57:42.253153Z",
     "iopub.status.busy": "2025-12-15T17:57:42.252670Z",
     "iopub.status.idle": "2025-12-15T17:57:42.311493Z",
     "shell.execute_reply": "2025-12-15T17:57:42.310578Z"
    },
    "papermill": {
     "duration": 0.066413,
     "end_time": "2025-12-15T17:57:42.312850",
     "exception": false,
     "start_time": "2025-12-15T17:57:42.246437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성공\n",
      "Submission file saved: submission.csv\n",
      "Submission file shape: (962, 6)\n",
      "Preview first few rows:\n",
      "         video_id agent_id target_id    action  start_frame  stop_frame\n",
      "row_id                                                                 \n",
      "0       438887472   mouse1    mouse2  approach          711         717\n",
      "1       438887472   mouse1    mouse2    submit          726         746\n",
      "2       438887472   mouse1    mouse2    attack          854         876\n",
      "3       438887472   mouse1    mouse2    submit          887         935\n",
      "4       438887472   mouse1    mouse2    submit          941         947\n"
     ]
    }
   ],
   "source": [
    "if CFG.mode == 'validate':  \n",
    "    submission = pd.concat(submission_list)\n",
    "    submission_robust = robustify(submission, train, 'train')\n",
    "    solution = create_solution_df(train_without_mabe22)\n",
    "    print(f\"Competition metric: {score(solution, submission_robust, ''):.4f}\")\n",
    "\n",
    "    # 修改：根据新的f1_list格式调整DataFrame创建\n",
    "    # 新的f1_list格式可能是 (body_parts_tracked_str, action, f1, threshold)\n",
    "    if f1_list and len(f1_list[0]) == 4:  # 四元组格式\n",
    "        f1_df = pd.DataFrame(f1_list, columns=['body_parts_tracked_str', 'action', 'binary F1 score', 'threshold'])\n",
    "    else:  # 三元组格式（兼容旧版本）\n",
    "        f1_df = pd.DataFrame(f1_list, columns=['body_parts_tracked_str', 'action', 'binary F1 score'])\n",
    "    \n",
    "    print(f\"Mean F1:            {f1_df['binary F1 score'].mean():.4f}\")\n",
    "  \n",
    "    # 修改：确保使用正确的模型名称路径\n",
    "    os.makedirs(CFG.model_name, exist_ok=True)  # 确保directory存在\n",
    "    joblib.dump(thresholds, f\"{CFG.model_name}/thresholds.pkl\")\n",
    "    joblib.dump(f1_df, f\"{CFG.model_name}/scores.pkl\")\n",
    "    print(f\"Model and thresholds saved to {CFG.model_name}/ directory\")\n",
    "\n",
    "if CFG.mode == 'submit':\n",
    "    if len(submission_list) > 0:\n",
    "        submission = pd.concat(submission_list)\n",
    "    else:\n",
    "        # 提供默认值以防万一\n",
    "        submission = pd.DataFrame({\n",
    "            'video_id': [438887472],\n",
    "            'agent_id': ['mouse1'],\n",
    "            'target_id': ['self'], \n",
    "            'action': ['rear'],\n",
    "            'start_frame': [278],\n",
    "            'stop_frame': [500]\n",
    "        })\n",
    "        \n",
    "    submission_robust = robustify(submission, test, 'test')\n",
    "    submission_robust.index.name = 'row_id'\n",
    "    \n",
    "    # 保存提交文件\n",
    "    submission_robust.to_csv('submission.csv', index=True)\n",
    "    print(f\"Submission file saved: submission.csv\")\n",
    "    print(f\"Submission file shape: {submission_robust.shape}\")\n",
    "    print(\"Preview first few rows:\")\n",
    "    print(submission_robust.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79cbfa09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T17:57:42.325395Z",
     "iopub.status.busy": "2025-12-15T17:57:42.324747Z",
     "iopub.status.idle": "2025-12-15T17:57:42.378957Z",
     "shell.execute_reply": "2025-12-15T17:57:42.377969Z"
    },
    "papermill": {
     "duration": 0.061569,
     "end_time": "2025-12-15T17:57:42.380090",
     "exception": false,
     "start_time": "2025-12-15T17:57:42.318521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved: submission.csv\n",
      "Submission file shape: (962, 6)\n",
      "Preview first few rows:\n",
      "         video_id agent_id target_id    action  start_frame  stop_frame\n",
      "row_id                                                                 \n",
      "0       438887472   mouse1    mouse2  approach          711         717\n",
      "1       438887472   mouse1    mouse2    submit          726         746\n",
      "2       438887472   mouse1    mouse2    attack          854         876\n",
      "3       438887472   mouse1    mouse2    submit          887         935\n",
      "4       438887472   mouse1    mouse2    submit          941         947\n"
     ]
    }
   ],
   "source": [
    "if len(submission_list) > 0:\n",
    "    submission = pd.concat(submission_list)\n",
    "else:\n",
    "    # 提供默认值以防万一\n",
    "    submission = pd.DataFrame({\n",
    "        'video_id': [438887472],\n",
    "        'agent_id': ['mouse1'],\n",
    "        'target_id': ['self'], \n",
    "        'action': ['rear'],\n",
    "        'start_frame': [278],\n",
    "        'stop_frame': [500]\n",
    "    })\n",
    "        \n",
    "submission_robust = robustify(submission, test, 'test')\n",
    "submission_robust.index.name = 'row_id'\n",
    "    \n",
    "# 保存提交文件\n",
    "submission_robust.to_csv('submission.csv', index=True)\n",
    "print(f\"Submission file saved: submission.csv\")\n",
    "print(f\"Submission file shape: {submission_robust.shape}\")\n",
    "print(\"Preview first few rows:\")\n",
    "print(submission_robust.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13874099,
     "sourceId": 59156,
     "sourceType": "competition"
    },
    {
     "datasetId": 9030522,
     "sourceId": 14167256,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "seoulstation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1241.244049,
   "end_time": "2025-12-15T17:57:43.304559",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-15T17:37:02.060510",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
